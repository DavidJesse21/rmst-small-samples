---
title: "Resampling-based Inference for Restricted Mean Survival Times"
author:
  - "David Jesse\\newline"
  - "First supervisor: Prof. Dr. Tim Friede\\newline"
  - "Second supervisor: Dr. Cynthia Huber"
date: 2024-04-02
date-format: "DD MMMM, YYYY"
latex-min-runs: 2
format: 
  beamer: 
    aspectratio: 169
    pdf-engine: pdflatex
    slide-level: 2
    toc: false
    include-in-header: 
      - ./tex/preamble.tex
      - ./tex/operators.tex
    keep-tex: false
execute: 
  eval: true
  echo: false
  output: true
  warning: false
---

```{r}
#| label: setup
#| include: false

box::use(
  ggplot2[...],
  data.table[...],
  survival[Surv, survfit],
  here[here],
  fs
)

setwd(here())
options(box.path = "R")

box::use(
  simfuns2/analyze[calc_rejection_rates, calc_ci_metrics, setj_samples_alloc, setj_percent],
  simfuns2/get_funs[get_scenario_table],
  plotting/surv[plot_surv_models],
  plotting/cens[plot_cens_models]
)


# Simulation results
dtr = readRDS(fs$path("simulation", "results", "2024-02-04_results", ext = "rds"))
setDT(dtr)
dts = get_scenario_table()


# Function for visualising Kaplan-Meier curve and restricted mean survival time
ggrmst = function(fit, cutoff,
                  color = "#0072B2", linewidth = 1, alpha = 0.3,
                  ...) {
  # Extract survival data
  dt_surv = data.table(
    time = c(0, fit$time),
    surv = c(1, fit$surv)
  )
  
  # Plot of the survival curve
  p = ggplot(dt_surv, aes(time, surv)) +
    geom_step(linewidth = linewidth, color = color)
  
  # Create data.table for plotting RMST
  dt_rmst = dt_surv[time <= cutoff]
  # Area should be drawn until the specified cutoff and not end before
  if (dt_rmst[.N, time < cutoff]) {
    dt_rmst = rbindlist(list(
      dt_rmst, data.table(time = cutoff, surv = dt_rmst[.N, surv])
    ))
  }
  # For geom_ribbon()
  dt1 = copy(dt_rmst)[, id := "b"]
  dt2 = copy(dt_rmst)[, id := "a"]
  dt2[, surv := shift(surv)]
  dt_rmst = rbindlist(list(dt1, dt2))
  setorder(dt_rmst, time, id)

  # Plot RMST
  p = p +
    geom_ribbon(
      aes(x = time, ymin = 0, ymax = surv), data = dt_rmst,
      fill = color, alpha = alpha
    ) +
    geom_vline(
      xintercept = cutoff,
      linetype = "dashed", color = "#333333", linewidth = 0.75 * linewidth
    )
  
  return(p)
}


# Default ggplot2 theme
theme_set(theme_bw(base_size = 16))
```

## Overview

- restricted mean survival time (RMST) contrasts as alternative effect measures to the hazard ratio (HR) for time-to-event endpoints

- two-sample comparisons under small to moderate sample sizes

- comparison of different inference methods w.r.t. type-I error rate, power and CI coverage

- asymptotic and resampling-based methods


## Hazard Ratio

- hazard rate
$$
h(t) = \lim_{\Delta t \to 0}
\frac{P(t \leq T < t + \Delta t | T \geq t)}{\Delta t}
$$

- most common effect measure: hazard ratio (HR)
$$
HR(t) = h_1(t) / h_0(t) = \theta \quad \forall \, t
$$

- proportional hazards assumption

  - model-based effect measure

  - strong assumption and often violated in practice (e.g. in oncology trials)
  
- hard to interpret clinically, even if the PH assumption holds


## Restricted Mean Survival Time (RMST)

$$
\mu(t^*) = \expect[\min(T, t^*)] = \int_0^{t^*} S(u) \,du
$$

- expected survival within the (pre-)specified follow-up period from time $0$ to $t^*$

- circumvent the aforementioned issues with the hazard ratio

```{r}
#| label: rmst-plot
#| layout: [[-12, 60, -20]]
#| fig-height: 4

dt = survival::veteran
setDT(dt)
dt = dt[time <= 800]

fit = survfit(Surv(time, status) ~ 1, data = dt)

ggrmst(fit, cutoff = 350) +
  scale_x_continuous(
    name = "Time",
    breaks = seq(0, 800, by = 100)
  ) +
  scale_y_continuous(
    name = "Survival probability",
    breaks = seq(0, 1, by = 0.2)
  )
```


## Inference for RMST Contrasts

$$
H_0: \mu_1(t^*) - \mu_0(t^*) = 0 \quad \text{vs.} \quad H_1: \mu_1(t^*) - \mu_0(t^*) \neq 0
$$

- focus on two-sample comparisons in an RCT setting

- asymptotic test based on Kaplan-Meier estimator

  - inflation of type-I error under small to moderate sample sizes
  
- other approaches so far

  - Ditzhaus et al., 2023: studentized permutation method

  - (Horiguchi & Uno, 2020: "simple" permutation method)
  
  - (Zhou, 2021: empirical likelihood ratio)


## Goals of my Master's Thesis

- replicate results by Ditzhaus et al., 2023

  - asymptotic test and studentized permutation test

- propose further existing resampling-based approaches
  
  - pseudo-observations + asymptotic test
  
  - pseudo-observations + bootstrap test
  
- pseudo-observation approaches might have some advantages for further extensions

  - usage with and adjustment for (continuous) covariates
  
  - flexibility in general


# Methods

## Asymptotic Test

- studentized test statistic
$$
Z = \frac{\hat{\mu}_1(t^*) - \hat{\mu}_0(t^*)}{\sqrt{\Varhat[\hat{\mu}_1(t^*)] + \Varhat[\hat{\mu}_0(t^*)]}}
$$

- asymptotic distribution
$$
Z \danull N(0, 1)
$$

- statistical test
$$
\varphi^{(asy)} = \mathbf{1} \{|Z| > z_{1- \alpha/2} \}
$$
  - $z_{1- \alpha/2}$: $(1 - \alpha/2)$-quantile of the standard normal distribution


## Studentized Permutation Test

- relax the assumptions on the null distribution

- permutation of the treatment indicator in the original data ($B$ times)

- for each permuted data set compute the studentized test statistic
$$
Z^{\pi} =
\frac{| \hat{\mu}_1^{\pi}(t^*) - \hat{\mu}_0^{\pi}(t^*) |}{\sqrt{\Varhat[\hat{\mu}_1^{\pi}(t^*)] + \Varhat[\hat{\mu}_0^{\pi}(t^*)]}}
$$

- statistical test
$$
\varphi^{\pi} = \mathbf{1} \{|Z| > q_{1 - \alpha}^{\pi} \}
$$
  - $q_{1 - \alpha}^{\pi}$: $(1 - \alpha)$-quantile of the the permutation test statistics


## Pseudo-Observations (1)

- pseudo-observations for estimand of interest
$$
P_i = n \hat{\theta} - (n - 1) \hat{\theta}_{-i}
$$
  - $\hat{\theta}$: marginal estimator
  
  - $\hat{\theta}_{-i}$: jackknife leave-one-out estimator
  
- use regression models on the pseudo-observations to estimate covariate/treatment effects

  - generalized estimating equations (GEE) / quasi-likelihood methods
  
  - robust covariance matrix estimator for inference, e.g. HC3

---

- test statistic
$$
Z = \frac{\betahat}{\sehat(\betahat)}
$$

- statistical test
$$
\varphi^{\text{(PO)}} = \mathbf{1} \{|Z| > z_{1- \alpha/2} \}
$$
  
- dependent censoring

  - categorical covariates: stratified computation
  
  - continuous covariates: IPCW approaches

## Pseudo-Observations (2)

- idea: refine PO approach by using a bootstrap test

  - relaxation of assumption on null distribution

- nonparametric bootstrap / case resampling

- for each bootstrap resample compute the test statistic
$$
Z^b = 
\frac{| \betahat^b - \betahat |}{\sehat(\betahat^b)}
$$

- statistical test
$$
\varphi^b = \mathbf{1} \{|Z| > q_{1 - \alpha}^b \}
$$
  - $q_{1 - \alpha}^b$: $(1 - \alpha)$-quantile of the the bootstrap test statistics

---

- problem: involved computation

  - nested resampling: bootstrap resampling (1), pseudo-observations (2)

- infinitesimal jackknife pseudo-observations
$$
\begin{split}
  P_i &= n \hat{\theta} - (n - 1) \hat{\theta}_{-i} \\
  &= \hat{\theta} + (n - 1) (\hat{\theta} - \hat{\theta}_{-i}) \\
  &\approx \hat{\theta} + n \frac{\partial \hat{\theta}}{\partial w_i}
\end{split}
$$


# Simulation Study

## Settings

- adapted from Ditzhaus et al., 2023

- survival models: PH (exponential), crossing (piece-wise exponential), crossing (Weibull, different shapes)

- censoring models: unequal Weibull, equal uniform, equal Weibull

- sample allocations: $(12, 18)$, $(15, 15)$, $(18, 12)$

- sample sizes: $K = 1, 2, 4, 6$

  - multiplication with base allocation
  
- RMST difference: $\Delta = 0, 1.5$ ($t^* = 10$)

- 216 settings in total with 5000 simulation replications

---

```{r}
#| label: surv-models
#| fig-height: 4.5

plot_surv_models(linewidth = 1.1, align = "h")
```

---

```{r}
#| label: cens-models
#| fig-height: 4.5

plot_cens_models(linewidth = 1.1, align = "h")
```


## Computation & Reproducibility

- `R` version `4.3.0` on the GWDG HPC cluster

- `{renv}` package for package and project management

- `{withr}` and `{parallel}` packages and L'Ecuyer-CMRG RNG for reproducible stochastic (parallel) computations

- methods

  - majority of functions/methods implemented by myself with some help/code provided by Prof. Marc Ditzhaus
  
  - `{eventglm}` for fitting PO regression models
  
  - approximate pseudo-observations: `survfit()` and `pseudo()` functions from package `{survival}`

- source code available on GitLab upon request


## Results - Type-I Error

```{r}
#| label: plot-type1error
#| fig-height: 4.5

dt1 = calc_rejection_rates(
  dtr[scenario.id %in% dts[rmst_diff == 0, scenario.id] & algo.id != 4],
  stats_NA = FALSE
)
dt1 = merge(
  dt1, dts[rmst_diff == 0, .(scenario.id, num_samples = n0 + n1)],
  by = "scenario.id"
)
setj_percent(dt1, "reject")

ggplot(dt1, aes(factor(algo.id), reject)) +
  geom_boxplot() +
  # Binomial confidence interval
  geom_hline(yintercept = 4.4, linetype = "dashed") +
  geom_hline(yintercept = 5.6, linetype = "dashed") +
  # Labels etc.
  scale_y_continuous(
    name = "Type I error in %\n"
  ) +
  scale_x_discrete(
    name = "\nMethods",
    labels = c("Asy", "St Perm", "PO Asy", "PO Boot")
  ) +
  # Differentiate between total sample sizes
  facet_wrap(
    ~ num_samples,
    labeller = labeller(num_samples = \(x) paste0("N = ", x))
  )
```


## Results - Power

```{r}
#| label: plot-power
#| fig-height: 4.5

dt2 = calc_rejection_rates(
  dtr[scenario.id %in% dts[rmst_diff == 1.5, scenario.id] & algo.id != 4],
  stats_NA = FALSE
)
dt2 = merge(
  dt2, dts[rmst_diff == 1.5, .(scenario.id, num_samples = n0 + n1)],
  by = "scenario.id"
)
setj_percent(dt2, "reject")

ggplot(dt2, aes(factor(algo.id), reject)) +
  geom_boxplot() +
  scale_y_continuous(
    name = "Power in %\n"
  ) +
  scale_x_discrete(
    name = "\nMethods",
    labels = c("Asy", "St Perm", "PO Asy", "PO Boot")
  ) +
  facet_wrap(
    ~ num_samples,
    labeller = labeller(num_samples = \(x) paste0("N = ", x)),
    scales = "free_y"
  )
```


## Results - Coverage

```{r}
#| label: plot-coverage
#| fig-height: 4.5

dt3 = calc_ci_metrics(
  merge(dtr[algo.id != 4], dts[, .(scenario.id, rmst_diff)], by = "scenario.id"),
  stats_NA = FALSE
)
dt3 = merge(
  dt3, dts[, .(scenario.id, num_samples = n0 + n1)],
  by = "scenario.id"
)
setj_percent(dt3, "coverage")

ggplot(dt3, aes(factor(algo.id), coverage)) +
  geom_boxplot() +
  theme_bw() +
  scale_y_continuous(
    name = "Coverage in %\n"
  ) +
  scale_x_discrete(
    name = "\nMethods",
    labels = c("Asy", "St Perm", "PO Asy", "PO Boot")
  ) +
  facet_wrap(
    ~ num_samples,
    labeller = labeller(num_samples = \(x) paste0("N = ", x))
  ) +
  # Binomial confidence interval
  geom_hline(yintercept = 94.4, linetype = "dashed") +
  geom_hline(yintercept = 95.6, linetype = "dashed")
```


# Summary & Outlook

## Summary 

- RMST contrasts as alternative effect measures instead of hazard ratio

- inflated type-I error rate for standard asymptotic RMST test

- resampling-based approaches could be shown to be a remedy for this

- proposed pseudo-observation approaches are valid alternatives to studentized permutation test with some potential advantages

  - straightforward covariate adjustment (increase in precision and power)
  
  - easy extension to other related settings (competing risks, effect measures, study designs)


## Outlook

- systematic investigation and comparison of covariate adjusted approaches

- alternatives to the nonparametric bootstrap for PO regression models

  - e.g. wild bootstrap

  - theoretical justification and empirical performance

- extension to other testing problems with more than two groups

  - global test and multiple comparisons

# Questions?
