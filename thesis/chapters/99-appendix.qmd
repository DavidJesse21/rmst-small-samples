# Appendices {.unnumbered}

\renewcommand{\thesubsection}{\Alph{subsection}}
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}


## Additional Simulation Results {#sec-sim-results2}

In the following, we present the simulation results for the pseudo-observations method using an asymptotic test that we have already presented in @sec-sim-results.
We compare these results to those using the same asymptotic procedure but based on infinitesimal jackknife (IJ) pseudo-observations that we have used for the bootstrap method introduced in @sec-po-boot.
The purpose is to get an impression of how the usage of IJ pseudo-observations instead of ordinary ones impacts the behavior of the testing procedure.

In general, the results suggest that the impact of using IJ pseudo-observations instead of ordinary pseudo-observations is rather low as the type I error rates and the power values are fairly similar.
Looking at the plot of the coverage rates (@fig-coverage-pseudo), however, we can see that for very small ($K = 1$) and unbalanced sample sizes there is a small impact.
In this sense, the usage of ordinary pseudo-observations is still favorable whenever feasible.
Nonetheless, the present results suggest that the differences in the operating characteristics between the asymptotic test using ordinary and the bootstrap test using IJ pseudo-observations shown in @sec-sim-results can primarily attributed to the nonparametric bootstrap procedure.

```{r}
#| label: tbl-type1err-pseudo
#| tbl-cap: "Type I error rates in % (nominal level $\\alpha = 5\\\\%$) of asymptotic tests using ordinary and infinitesimal jackknife pseudo-observations. The values inside the binomial confidence interval $[4.4\\\\%, 5.6\\\\%]$ are printed bold"

# Here we are interested in the comparison of ordinary and IJ pseudo-observations
dt_err = calc_rejection_rates(
  dtr[scenario.id %in% dts[rmst_diff == 0, scenario.id] & algo.id %in% 3:4],
  stats_NA = FALSE
)
dt_err = merge(dt_err, dts[rmst_diff == 0], by = "scenario.id")

# For latex, directly starting off with a table in wide format might be easier
dt_err = dcast(dt_err, scenario.id ~ algo.id, value.var = "reject")
setnames(dt_err, old = as.character(3:4), new = paste0("algo", 3:4))

# Append scenario information...
dt_err = merge(dt_err, dts, by = "scenario.id")
setj_percent(dt_err, paste0("algo", 3:4))
for (j in paste0("algo", 3:4)) {
  set(dt_err, j = j, value = round(dt_err[[j]], 1))
}
dt_err[, samples_alloc := factor(
  sprintf("n_%d_%d", n0 / samples_k, n1 / samples_k),
  levels = sprintf("n_%d_%d", c(12, 15, 18), c(18, 15, 12))
)]
# ... but some columns are or have become redundant
for (j in c("scenario.id", "rmst_diff", "n0", "n1")) {
  set(dt_err, j = j, value = NULL)
}

dt_err = dcast(
  dt_err,
  surv_model + cens_model + samples_k ~ samples_alloc, value.var = paste0("algo", 3:4)
)

# Order columns and rows
setcolorder(
  dt_err, neworder = c(
    "surv_model", "cens_model", "samples_k",
    sprintf("algo%d_n_12_18", 3:4),
    sprintf("algo%d_n_15_15", 3:4),
    sprintf("algo%d_n_18_12", 3:4)
  )
)
dt_err[, `:=`(
  surv_model = factor(surv_model, levels = c("ph_exp", "crossing_pwexp", "crossing_wb")),
  cens_model = factor(cens_model, levels = c("uneq_wb", "eq_unif", "eq_wb"))
)]
setorder(dt_err, surv_model, cens_model, samples_k)

# Make some cells of column `cens_model` empty
na_idx = setdiff(1:nrow(dt_err), seq(1, nrow(dt_err), by = 4))
dt_err[na_idx, cens_model := NA]

# Also need to relabel this
dt_err[, cens_model := as.character(cens_model)]
dt_err[, cens_model := fcase(
  cens_model == "uneq_wb", "un. W.",
  cens_model == "eq_unif", "eq. U.",
  cens_model == "eq_wb", "eq. W."
)]

# NAs as empty cells
options(knitr.kable.NA = '')

# Conditional formatting
for (j in colnames(dt_err)[-(1:3)]) {
  set(
    dt_err, j = j, value = cell_spec(
      format(dt_err[[j]], digits = 1, nsmall = 1), bold = between(dt_err[[j]], 4.4, 5.6)
    )
  )
}


# latex table
kbl(
  copy(dt_err)[, surv_model := NULL],
  format = "latex",
  digits = 1,
  booktabs = TRUE,
  centering = TRUE,
  escape = FALSE,
  align = c("l", rep("c", 7)),
  col.names = c("Censoring", "K", rep(c(" PO ", "PO IJ"), 3)),
  linesep = c(rep("", 11), "\\hline")
) |>
  # Group the columns by their sample allocation
  add_header_above(
    setNames(
      c(1, 1, 2, 2, 2),
      c(" ", " ", sprintf(r"($N = K \\cdot (%d, %d)$)", c(12, 15, 18), c(18, 15, 12)))
    ),
    escape = FALSE, bold = TRUE
  ) |>
  # Column widths
  # Borders between the groups make it more accessible
  column_spec(1, width = "1.5cm") |>
  column_spec(2, border_right = TRUE, width = "1cm") |>
  column_spec(3, width = "1.5cm") |>
  column_spec(4, border_right = TRUE, width = "1.5cm") |>
  column_spec(5, width = "1.5cm") |>
  column_spec(6, border_right = TRUE, width = "1.5cm") |>
  column_spec(7:8, width = "1.5cm") |>
  # Group table (rows) by survival distributions
  pack_rows(
    "S1: Exponential distributions", 1, 12,
    bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
  ) |>
  pack_rows(
    "S7: Exponential and piecewise exponential distributions with crossing curves", 13, 24,
    bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
  ) |>
    pack_rows(
      "S8: Weibull distributions with crossing curves and shape alternatives", 25, 36,
      bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
    ) |>
  # Make it more accessible using stripes option
  kable_styling(
    latex_options = c("striped"),
    stripe_index = c(5:8, 17:20, 29:32),
    stripe_color = "#e9ecef",
    font_size = 10
  ) |>
  # Explain binomial confidence interval and abbreviations
  footnote(
    general = c(
      # paste0(
      #   r"(\\textit{Note:} )",
      #   "The values inside the binomial confidence interval [4.4\\\\%, 5.6\\\\%] are printed bold."
      # ),
      paste0(
        r"(\\textit{Abbreviations:} )",
        "PO, ordinary jackknife pseudo-observations; ",
        "PO IJ, infinitesimal jackknife pseudo-observations; ",
        "un. W., unequal Weibull censoring; ",
        "eq. U., equal uniform censoring; ",
        "eq. W., equal Weibull censoring."
      )
    ),
    general_title = "",
    escape = FALSE,
    threeparttable = TRUE
  )
```

```{r}
#| label: tbl-power-pseudo
#| tbl-cap: "Rejection rates (power) in % (nominal level $\\alpha = 5\\\\%$) of asymptotic tests using ordinary and infinitesimal jackknife pseudo-observations"

# Calculate rejection rates (power)
# Here we are interested in the comparison of ordinary and IJ pseudo-observations
dt_pow = calc_rejection_rates(
  dtr[scenario.id %in% dts[rmst_diff == 1.5, scenario.id] & algo.id %in% 3:4],
  stats_NA = FALSE
)
dt_pow = merge(dt_pow, dts[rmst_diff == 1.5], by = "scenario.id")


# For latex, directly starting off with a table in wide format might be easier
dt_pow = dcast(dt_pow, scenario.id ~ algo.id, value.var = "reject")
setnames(dt_pow, old = as.character(3:4), new = paste0("algo", 3:4))

# Append scenario information...
dt_pow = merge(dt_pow, dts, by = "scenario.id")
setj_percent(dt_pow, paste0("algo", 3:4))
for (j in paste0("algo", 3:4)) {
  set(dt_pow, j = j, value = round(dt_pow[[j]], 1))
}
dt_pow[, samples_alloc := factor(
  sprintf("n_%d_%d", n0 / samples_k, n1 / samples_k),
  levels = sprintf("n_%d_%d", c(12, 15, 18), c(18, 15, 12))
)]
# ... but some columns are or have become redundant
for (j in c("scenario.id", "rmst_diff", "n0", "n1")) {
  set(dt_pow, j = j, value = NULL)
}

dt_pow = dcast(
  dt_pow,
  surv_model + cens_model + samples_k ~ samples_alloc, value.var = paste0("algo", 3:4)
)

# Order columns and rows
setcolorder(
  dt_pow, neworder = c(
    "surv_model", "cens_model", "samples_k",
    sprintf("algo%d_n_12_18", 3:4),
    sprintf("algo%d_n_15_15", 3:4),
    sprintf("algo%d_n_18_12", 3:4)
  )
)
dt_pow[, `:=`(
  surv_model = factor(surv_model, levels = c("ph_exp", "crossing_pwexp", "crossing_wb")),
  cens_model = factor(cens_model, levels = c("uneq_wb", "eq_unif", "eq_wb"))
)]
setorder(dt_pow, surv_model, cens_model, samples_k)

# Make some cells of column `cens_model` empty
na_idx = setdiff(1:nrow(dt_pow), seq(1, nrow(dt_pow), by = 4))
dt_pow[na_idx, cens_model := NA]

# Also need to relabel this
dt_pow[, cens_model := as.character(cens_model)]
dt_pow[, cens_model := fcase(
  cens_model == "uneq_wb", "un. W.",
  cens_model == "eq_unif", "eq. U.",
  cens_model == "eq_wb", "eq. W."
)]


# NAs as empty cells
options(knitr.kable.NA = '')

# latex table
kbl(
  copy(dt_pow)[, surv_model := NULL],
  format = "latex",
  digits = 1,
  booktabs = TRUE,
  centering = TRUE,
  escape = FALSE,
  align = c("l", rep("c", 7)),
  col.names = c("Censoring", "K", rep(c(" PO ", "PO IJ"), 3)),
  linesep = c(rep("", 11), "\\hline")
) |>
  # Group the columns by their sample allocation
  add_header_above(
    setNames(
      c(1, 1, 2, 2, 2),
      c(" ", " ", sprintf(r"($N = K \\cdot (%d, %d)$)", c(12, 15, 18), c(18, 15, 12)))
    ),
    escape = FALSE, bold = TRUE
  ) |>
  # Column widths
  # Borders between the groups make it more accessible
  column_spec(1, width = "1.5cm") |>
  column_spec(2, border_right = TRUE, width = "1cm") |>
  column_spec(3, width = "1.5cm") |>
  column_spec(4, border_right = TRUE, width = "1.5cm") |>
  column_spec(5, width = "1.5cm") |>
  column_spec(6, border_right = TRUE, width = "1.5cm") |>
  column_spec(7:8, width = "1.5cm") |>
  # Group table (rows) by survival distributions
  pack_rows(
    "S1: Exponential distributions", 1, 12,
    bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
  ) |>
  pack_rows(
    "S7: Exponential and piecewise exponential distributions with crossing curves", 13, 24,
    bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
  ) |>
    pack_rows(
      "S8: Weibull distributions with crossing curves and shape alternatives", 25, 36,
      bold = FALSE, latex_gap_space = "0.5em", hline_after = TRUE
    ) |>
  # Make it more accessible using stripes option
  kable_styling(
    latex_options = c("striped"),
    stripe_index = c(5:8, 17:20, 29:32),
    stripe_color = "#e9ecef",
    font_size = 10
  ) |>
  # Explain binomial confidence interval and abbreviations
  footnote(
    general = c(
      paste0(
        r"(\\textit{Abbreviations:} )",
        "PO, ordinary jackknife pseudo-observations; ",
        "PO IJ, infinitesimal jackknife pseudo-observations; ",
        "un. W., unequal Weibull censoring; ",
        "eq. U., equal uniform censoring; ",
        "eq. W., equal Weibull censoring."
      )
    ),
    general_title = "",
    escape = FALSE,
    threeparttable = TRUE
  )
```

\newpage

```{r}
#| label: fig-coverage-pseudo
#| fig-cap: "Confidence interval coverage of asymptotic methods using ordinary and infinitesimal jackknife pseudo-observations in % (nominal level $\\alpha = 5\\%$) aggregated by sample allocations ($(n_0, n_1)$) and their multipliers ($K$). The dashed lines depict the 95% binomial confidence interval $[94.4\\%, 95.6\\%]$"
#| fig-scap: "Confidence interval coverage of asymptotic methods using ordinary and infinitesimal jackknife pseudo-observations in % (nominal level $\\alpha = 5\\%$) aggregated by sample allocations ($(n_0, n_1)$) and their multipliers ($K$)"
#| fig-width: 10
#| fig-height: 10


dt5 = calc_ci_metrics(
  merge(dtr[algo.id %in% 3:4], dts[, .(scenario.id, rmst_diff)], by = "scenario.id"),
  stats_NA = FALSE
)
dt5 = merge(dt5, dts[, .(scenario.id, samples_k, n0, n1)], by = "scenario.id")
setj_percent(dt5, "coverage")
setj_samples_alloc(dt5)

ggplot(dt5, aes(factor(algo.id), coverage)) +
  geom_boxplot() +
  facet_grid(
    rows = vars(samples_k), cols = vars(samples_alloc),
    labeller = labeller(
      samples_k = \(x) sprintf("K = %s", x),
      samples_alloc = \(x) sprintf("n = %s", x)
    )
  ) +
  # Binomial confidence interval
  geom_hline(yintercept = 94.4, linetype = "dashed") +
  geom_hline(yintercept = 95.6, linetype = "dashed") +
  # y-axis
  scale_y_continuous(
    name = "Coverage in %\n"
  ) +
  # x-axis
  scale_x_discrete(
    name = "\nMethods",
    labels = c("PO", "PO IJ")
  )
```