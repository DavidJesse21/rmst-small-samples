---
bibliography: ["../bib/references.bib", "../bib/packages.bib"]
---

# Survival Analysis under Non-proportional Hazards {#sec-survnph}

In this section, we present some fundamental concepts and quantities used in survival analysis and in doing so introduce the basic notation used throughout this thesis, for which we orientate ourselves towards @collett2015[Chapter 1] and @bardo2024.
Moreover, a special emphasis is placed on the prevalence of the proportional hazards assumption in survival analysis.
Eventually, we introduce the restricted mean survival time as a model-free summary measure that can be used for analyzing survival data under non-proportional hazards.


## Notation and Basic Concepts {#sec-basics}

Let $T \in \real^{+}$ denote a random variable for the time to event and $C \in \real^{+}$ a second random variable for the censoring time.
In real-world applications, $T$ and $C$ are never observed simultaneously.
Instead, for an individual $i$ we only observe $t_i = \min(T_i, C_i)$.
Furthermore, we record if the event has been observed for an individual or is censored using the event indicator $\delta_i = \mathbf{1} \{T_i \leq C_i\}$.
Thus, ignoring potential covariates, the time-to-event outcome of a single observation consists of the tuple $(t_i,\, \delta_i)$.
This thesis focuses on two-sample settings in clinical trials.
For this reason, we introduce the treatment indicator variable $Z \in \{0, 1\}$ where $Z = 1$ denotes the experimental and $Z = 0$ the control treatment group.
Alternatively, the group associations may also be indicated using the subscript $j$ with the same attributions as for $Z$.
Lastly, $\xvec_i \in \real^{p}$ is used for denoting a vector of $p$ covariates associated with an individual $i$.
Besides the treatment assignment, this vector might record other characteristics of interest such as the age of a patient.
Correspondingly, $\xmat \in \real^{n \times p}$ denotes the design matrix for a whole sample of size $n$.[^1]

The random variable $T$ can be characterized by its *distribution function*
$$
F(t) = \prob(T \leq t) = \int_0^t f(u) \, du \, ,
$$ {#eq-distr}
with $f$ being the *density function* of that random variable.
The distribution function has the interpretation as the probability of the random survival time $T$ being less than or equal to some value $t$ and is therefore also  referred to as the *cumulative incidence function* in the context of survival analysis.
Often, however, the interpretation of the *survival function* appears to be more intuitive, which is just one minus the distribution function, i.e.
$$
S(t) = 1 - F(t) = \prob(T > t) \, .
$$ {#eq-surv}
Hence, it describes the probability of surviving beyond some time point $t$.
Another important function used in survival analysis is the *hazard function*.
Its formal definition is
$$
h(t) = \lim_{\Delta t \to 0}
\frac{\prob(t \leq T < t + \Delta t | T \geq t)}{\Delta t}
\, ,
$$ {#eq-hazard}
where $\Delta t$ denotes an increment of time.
Since we are considering the limit $\Delta t \to 0$ the hazard function can be understood as the instantaneous failure rate at some time point $t$ and is therefore also called the *hazard rate*.
From the hazard rate, the *cumulative hazard function* can be derived:
$$
H(t) = \int_0^t h(u) \, du
$$ {#eq-cumhaz}
The cumulative hazard function can be interpreted as the "cumulative risk of an event by time $t$" [@collett2015, Chapter 1].
Among practitioners, the interpretation of the latter two quantities is often unclear and can lead to confusion.
Their usefulness, however, lies in their interrelation with $f(t)$, $F(t)$ and $S(t)$, respectively.
Using standard results from probability theory, the following results can be obtained, among others:
$$
\begin{split}
  &h(t) = \frac{f(t)}{S(t)} \\
  &S(t) = \exp(- H(t))
\end{split}
$$
Accordingly, if one of the aforementioned functions is given all of the remaining ones can be derived from it.
Many of the methods employed in survival analysis are actually built upon the hazard function.
Its relevance shall be further underlined in the following subsection.


## Non-proportional Hazards {#sec-nph}

We now consider a setting with two independent populations, e.g. one coming from a control ($j = 0$) and the other coming from an experimental ($j = 1$) treatment group in a clinical trial:
$$
T_{j} \sim S_j \quad (j = 0, 1)
$$
As pointed out in the previous subsection, the distributional assumptions could also be expressed in terms of the hazard functions.
Given these, we can define the relative hazard between the experimental and the control group, more commonly known as the *hazard ratio*:
$$
HR(t) = \frac{h_1(t)}{h_0(t)} \quad \text{for } h_0(t) > 0
$$ {#eq-hr}
Using this general definition, it is clear that the hazard ratio is a function of time.
However, many of the standard statistical methods used in survival analysis are based on the assumption that the hazards are proportional over time, implying that the hazard ratio is independent of it:
$$
HR(t) = \frac{h_1(t)}{h_0(t)} = \theta \quad \forall \, t
$$ {#eq-phr}
Here, $\theta \in (0, \infty)$ is some constant highlighting this assumption, which is known as the *proportional hazards* (PH) assumption.
This assumption may or may not hold, which can be illustrated using the Weibull distribution as a theoretical example.
The hazard function of the Weibull distribution is [@kalbfleisch2002, Chapter 2.2]
$$
h(t) = \lambda \alpha (\lambda t)^{\alpha - 1}
\, ,
$$ {#eq-wb-hazard}
with *shape* parameter $\alpha$ and *scale* parameter $\lambda$.
For the hazard ratio, we then have:
$$
\begin{split}
  \frac{h_1(t)}{h_0(t)} &=
  \frac{\lambda_1 \alpha_1 (\lambda_1 t)^{\alpha_1 - 1}}{\lambda_0 \alpha_0 (\lambda_0 t)^{\alpha_0 - 1}} \\
  &= \frac{\lambda_1^{\alpha_1} \alpha_1}{\lambda_0^{\alpha_0} \alpha_0} \cdot
  \frac{t^{\alpha_1 - 1}}{t^{\alpha_0 - 1}}
\end{split}
$$
Here, we can see that the Weibull distribution exhibits proportional hazards if the shape parameter is the same for both populations, i.e. $\alpha_0 = \alpha_1 = \alpha$.
In this case, the hazard ratio is given by $(\lambda_1 / \lambda_0)^\alpha$.
If this is not the case, however, the hazards are non-proportional.
@fig-nph illustrates those two situations, depicting the survival and hazard functions as well as the hazard ratio of the two groups with differently parametrized Weibull distributions.

```{r}
#| label: fig-nph
#| fig-cap: "Weibull survival models of two populations with different parameter values. In the left column the shape parameters of the two populations are equal, resulting in a scenario with proportional hazards. In the right column the shape parameters differ, implying non-proportional hazards"
#| fig-scap: "Weibull survival models of two populations with proportional (left) and non-proportional (right) hazards"
#| fig-width: 10
#| fig-height: 10

# Weibull survival functions (R parametrization)
wb_haz = function(x, shape, scale) {
  scale * shape * (scale * x)^(shape - 1)
}

wb_surv = function(x, shape, scale) {
  exp(- (scale * x)^shape)
}

wb_hr = function(x, shape1, scale1, shape0, scale0) {
  wb_haz(x, shape1, scale1) / wb_haz(x, shape0, scale0)
}


# Proportional hazards ----

shape0_1 = 3
scale0_1 = 8

shape1_1 = 3
scale1_1 = 9

# Constant ggplot objects
spec_xaxis = scale_x_continuous(
  breaks = seq(0, 10, by = 2.5),
  limits = c(0, 10.5),
  expand = expansion(mult = c(0, 0), add = c(0.25, 0.25))
)

spec_xtitle = xlab("\nTime")

spec_legend = scale_color_manual(
  name = NULL,
  values = c("T0" = "#E69F00", "T1" = "#56B4E9"),
  labels = c(
    expression(paste(T[0], " ~ Weib(3, 1/8)")),
    expression(paste(T[1], " ~ Weib(3, 1/9)"))
  )
)

# Plots
p1_surv = ggplot() +
  geom_function(
    aes(color = "T1"), fun = \(x) wb_surv(x, shape1_1, 1/scale1_1),
    linewidth = 1.1
  ) +
  geom_function(
    aes(color = "T0"), fun = \(x) wb_surv(x, shape0_1, 1/scale0_1),
    linewidth = 1.1
  ) +
  spec_legend +
  spec_xaxis +
  spec_xtitle +
  ylab("Survival Probability\n") +
  scale_y_continuous(limits = 0:1) +
  theme(legend.position = "top")

p1_haz = ggplot() +
  geom_function(
    aes(color = "T1"), fun = \(x) wb_haz(x, shape1_1, 1/scale1_1),
    linewidth = 1.1
  ) +
  geom_function(
    aes(color = "T0"), fun = \(x) wb_haz(x, shape0_1, 1/scale0_1),
    linewidth = 1.1
  ) +
  spec_legend +
  spec_xaxis +
  spec_xtitle +
  ylab("Hazard Rate\n") +
  theme(legend.position = "none")

p1_hr = ggplot() +
  geom_function(
    fun = \(x) wb_hr(x, shape1_1, 1/scale1_1, shape0_1, 1/scale0_1),
    linewidth = 1.1, color = "#000000"
  ) +
  spec_xaxis +
  spec_xtitle +
  ylab(expression(paste("Hazard Ratio ", h[0](t)/h[1](t), "\n"))) +
  theme(legend.position = "none") +
  scale_y_continuous(
    breaks = seq(0.6, 0.8, by = 0.05),
    limits = c(0.6, 0.8)
  )
  #scale_y_continuous(
  #  breaks = seq(1.35, 1.5, by = 0.05),
  #  limits = c(1.35, 1.5)
  #)


# Nonproportional hazards ----

shape0_2 = 3
scale0_2 = 8

shape1_2 = 2
scale1_2 = 9

spec_legend = scale_color_manual(
  name = NULL,
  values = c("T0" = "#E69F00", "T1" = "#56B4E9"),
  labels = c(
    expression(paste(T[0], " ~ Weib(3, 1/8)")),
    expression(paste(T[1], " ~ Weib(2, 1/9)"))
  )
)

# Plots
p2_surv = ggplot() +
  geom_function(
    aes(color = "T1"), fun = \(x) wb_surv(x, shape1_2, 1/scale1_2),
    linewidth = 1.1
  ) +
  geom_function(
    aes(color = "T0"), fun = \(x) wb_surv(x, shape0_2, 1/scale0_2),
    linewidth = 1.1
  ) +
  spec_legend +
  spec_xaxis +
  spec_xtitle +
  scale_y_continuous(limits = 0:1, name = NULL) +
  theme(legend.position = "top")

p2_haz = ggplot() +
  geom_function(
    aes(color = "T1"), fun = \(x) wb_haz(x, shape1_2, 1/scale1_2),
    linewidth = 1.1
  ) +
  geom_function(
    aes(color = "T0"), fun = \(x) wb_haz(x, shape0_2, 1/scale0_2),
    linewidth = 1.1
  ) +
  spec_legend +
  spec_xaxis +
  spec_xtitle +
  scale_y_continuous(name = NULL) +
  theme(legend.position = "none")

p2_hr = ggplot() +
  geom_function(
    fun = \(x) wb_hr(x, shape1_2, 1/scale1_2, shape0_2, 1/scale0_2),
    linewidth = 1.1, color = "#000000"
  ) +
  spec_xaxis +
  spec_xtitle +
  scale_y_continuous(name = NULL) +
  theme(legend.position = "none")


# Combine plots ----

wrap_plots(
  # Proportional hazards
  p1_surv, p1_haz, p1_hr,
  # Nonproportional hazards
  p2_surv, p2_haz, p2_hr
) +
  plot_layout(ncol = 2, byrow = FALSE, axes = "collect_x")
```

We can also use real-world data sets to contrast situations with hazards that are rather proportional or non-proportional over time.
Such examples are given in @fig-nph2 where the estimated survival and hazard functions are shown.
The former are estimated using the nonparametric Kaplan-Meier estimator of the survival function, while the latter are derived from fitting flexible parametric models [@royston2002] with $(3, 2)$ degrees of freedom.
Moreover, the time-varying hazard ratio derived from these estimates of the hazard functions is portrayed in the bottom row of the plot.
In addition to that, the dashed line represents the estimate of the time-independent hazard ratio obtained from the Cox model [@cox1972].

In the left column, we use the "diabetic" data set from the `{survival}` R package [@R-survival], which contains results from a trial of laser coagulation for the treatment of diabetic retinopathy.
We can see that the survival curves do not cross a single time and diverge fairly evenly across time.
Accordingly, the estimated hazard functions are proportional to the greatest extent.
Although the hazard ratio fluctuates somewhat in the initial phase of the study, it remains within a relatively small range overall, not deviating much from the constant hazard ratio obtained from the Cox model.

On the other hand, the data set presented in the right column is reconstructed from a phase-III randomized controlled trial by @robert2015.
Here, the population under investigation consisted of patients with advanced melanoma.
The treatments analyzed and compared with each other were dacarbazine and nivolumab.
In comparison to the "diabetic" data set, we can see that the estimated survival functions cross each other in the initial phase of the study multiple times.
After around 2.5 months we can observe an effect of the nivolumab therapy leading to a separation of the survival curves.
From the profile of the estimated hazard functions, we can also conclude that there is less support for assuming proportional hazards.
While the hazard function of the dacarbazine group monotonically increases over time, we can see that, for the nivolumab group, it increases in the first 2.5 months but decreases afterward.
Also, the curve of the time-dependent hazard ratio exhibits greater variability.

```{r}
#| label: fig-nph2
#| fig-scap: "Estimated survival functions with signs of proportional (left) and non-proportional (right) hazards"
#| fig-cap: 'Estimated survival functions for the R "diabetic" data set (left) and data reconstructed from @robert2015 (right). For the former the proportional hazards assumption can be considered plasuible, whereas the latter provides less support for making this assumption'
#| fig-width: 10
#| fig-height: 10

# FPM functions ----

fit_fpm = function(data, df1 = 3, df2 = 2) {
  li_anc = rep(list(~ group), df2)
  names(li_anc) = paste0("gamma", 1:df2)
  
  m = flexsurvspline(
    Surv(time, event) ~ group, data = data,
    k = df1 - 1, anc = li_anc
  )
  
  return(m)
}

plot_fpm = function(m, t_eval, type = c("survival", "hazard", "HR"), hr_order = 0:1, ...) {
  type = match.arg(type, c("survival", "hazard", "HR"))
  
  li_dt = summary(
    m,
    type = if (type == "survival") "survival" else "hazard",
    t = t_eval,
    ci = FALSE
  )
  
  invisible(lapply(li_dt, setDT))
  invisible(lapply(names(li_dt), function(x) {
    li_dt[[x]][, group := sub("group=(.*)", "\\1", x)]
  }))
  
  dt = rbindlist(li_dt)
  dt[, group := factor(group, levels = sub("group=(.*)", "\\1", names(li_dt)))]
  
  # Survival and hazards
  if (type %in% c("survival", "hazard")) {
    p = ggplot(dt, aes(time, est, color = group)) +
      geom_line(...)
  } else {
    # Hazard ratio
    dt = dcast(dt, time ~ group, value.var = "est")
    setnames(dt, old = 2:3, new = paste0("haz", hr_order))
    dt[, hr := haz0 / haz1]
    
    p = ggplot(dt, aes(time, hr)) +
      geom_line(...)
  }
  
  return(p)
}


# Proportional hazards (colon) ----

dt1 = survival::diabetic
setDT(dt1)

# Rename important columns
setnames(dt1, old = c("status", "trt"), new = c("event", "group"))

# Treatment variable needs to be categorical for FPM
dt1[, group := fifelse(group == 1, "Laser", "Control")]

# Kaplan-Meier curves
p_km1 = ggsurvfit(
  survfit2(Surv(time, event) ~ group, data = dt1),
  linewidth = 1.1
) +
  theme_bw(base_size = 16)

# FPM
m1 = fit_fpm(dt1)

# Cox HR
hr1 = coxph(Surv(time, event) ~ group, data = dt1)
hr1 = unname(exp(coef(hr1)))

# time points for evaluating survival functions
t_eval1 = seq(0.5, 70, by = 0.25)

# Survival functions based on FPM
p_h1 = plot_fpm(m1, t_eval1, "hazard", linewidth = 1.1)
p_hr1 = plot_fpm(m1, t_eval1, "HR", linewidth = 1.1, hr_order = 1:0)


# Non-proportional hazards ----

li_dt = lapply(c("nivo", "daca"), function(x) {
  file = here(fs$path("data", paste0("robert_", x), ext = "txt"))
  fread(file)
})
dt2 = rbindlist(li_dt)
setnames(dt2, new = c("time", "event", "group"))

# Kaplan-Meier curves
p_km2 = ggsurvfit(
  survfit2(Surv(time, event) ~ group, data = dt2),
  linewidth = 1.1
) +
  theme_bw(base_size = 16)

# FPM
m2 = fit_fpm(dt2)

# Cox HR
hr2 = coxph(Surv(time, event) ~ group, data = dt2)
hr2 = unname(exp(coef(hr2)))

# time points for evaluating survival functions
t_eval2 = seq(0.3, 15, by = 0.1)

# Survival functions based on FPM
p_h2 = plot_fpm(m2, t_eval2, "hazard", linewidth = 1.1)
p_hr2 = plot_fpm(m2, t_eval2, "HR", linewidth = 1.1)


# Plot jointly ----

blank_x = theme(
  axis.title.x = element_blank(),
  axis.text.x = element_blank(),
  axis.ticks.x = element_blank()
)

p_km1 = p_km1 +
  xlab(NULL) +
  blank_x +
  ylab("Survival Probability\n") +
  scale_color_manual(
    name = NULL,
    labels = c("Control", "Laser"),
    values = c("Control" = "#E69F00", "Laser" = "#56B4E9")
  ) +
  theme(legend.position = "top") +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 70))

p_h1 = p_h1 +
  xlab(NULL) +
  blank_x +
  ylab("Hazard Rate\n") +
  scale_color_manual(
    name = NULL,
    labels = c("Control", "Laser"),
    values = c("Control" = "#E69F00", "Laser" = "#56B4E9")
  ) +
  scale_x_continuous(limits = c(0, 70)) +
  theme(legend.position = "none")

p_hr1 = p_hr1 +
  xlab(NULL) +
  #ylab(expression(paste("Hazard Ratio ", h[0](t)/h[1](t), "\n"))) +
  ylab(expression(paste("Hazard Ratio ", h[1](t)/h[0](t), "\n"))) +
  scale_x_continuous(limits = c(0, 70)) +
  #scale_y_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 1.2)) +
  geom_hline(
    yintercept = hr1,
    linetype = "dashed",
    linewidth = 1
  )


p_km2 = p_km2 +
  xlab(NULL) +
  blank_x +
  ylab(NULL) +
  scale_color_manual(
    name = NULL,
    labels = c("Dacarbazine", "Nivolumab"),
    values = c("Dacarbazine" = "#E69F00", "Nivolumab" = "#56B4E9")
  ) +
  theme(legend.position = "top") +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 15))

p_h2 = p_h2 +
  xlab(NULL) +
  blank_x +
  ylab(NULL) +
  scale_color_manual(
    name = NULL,
    labels = c("Dacarbazine", "Nivolumab"),
    values = c("Dacarbazine" = "#E69F00", "Nivolumab" = "#56B4E9")
  ) +
  theme(legend.position = "none") +
  scale_x_continuous(limits = c(0, 15))

p_hr2 = p_hr2 +
  xlab(NULL) +
  ylab(NULL) +
  scale_x_continuous(limits = c(0, 15)) +
  #scale_y_continuous(limits = c(0, 6)) +
  scale_y_continuous(limits = c(0, 1.2)) +
  geom_hline(
    yintercept = hr2,
    linetype = "dashed",
    linewidth = 1
  )


wrap_plots(
  # Proportional hazards
  p_km1, p_h1, p_hr1,
  # Non-proportional hazards
  p_km2, p_h2, p_hr2
) +
  plot_layout(ncol = 2, byrow = FALSE, axes = "collect_x") &
  xlab("\nTime (months)")
```

Among the statistical models that employ the proportional hazards assumption, perhaps the best-known and most widely used one is the previously mentioned semiparametric *Cox proportional hazards model* [@cox1972]:
$$
h(t \,|\, Z) = \exp(\beta Z) h_0(t)
$$ {#eq-coxph}
The Cox model is a regression model for covariate effects on the hazard scale.
Here, we employ our previous notation, $h_0(t)$ being the hazard function of the control group and $Z$ being the treatment indicator with $Z = 1$ indicating an allocation to the experimental treatment group.
In this context, $\exp(\beta)$ can be interpreted as the hazard ratio as it has been defined in (@eq-phr).
Nonetheless, the Cox model (@eq-coxph) can be extended to the more general case of multiple covariates $\xvec$ of different types (categorical, continuous) and corresponding regression coefficients $\betavec$.
The interpretation of $h_0(t)$ would then also change to a more generic baseline hazard not solely attributed to the control treatment group.
The main reason for the popularity of the Cox model is its semiparametric nature:
While an estimate of the hazard ratio ($\exp(\beta)$) is obtained, the baseline hazard $h_0(t)$ does not need to be specified or even estimated at all.
This sets it apart from many parametric alternatives, such as accelerated failure time models, for which a strict assumption about the conditional distribution of $T$ needs to be made.
Since deciding on a plausible parametric distribution for time-to-event data is a difficult task in many practical applications, especially when this decision needs to be made a priori, the Cox model and the hazard ratio have become the default choice for effect estimation in these settings.
Nonetheless, the strong assumption of proportional hazards persists, which is why some authors have become more skeptical about its usage for effect estimation [@royston2011].

Another routine method used in survival analysis is the log-rank test [@peto1972].
It is a non-parametric test for the hypotheses
$$
H_0: S_1(t) = S_0(t) \; \text{for all } t \quad \text{vs.} \quad
H_1: S_1(t) \neq S_0(t) \; \text{for at least one } t
\, .
$$ {#eq-lrtest-problem}
While the log-rank test for the testing problem (@eq-lrtest-problem) is valid under both, proportional and non-proportional hazards, it loses power in the case of NPH [@rufibach2019].
However, the bigger issue can be considered the fact that the underlying estimand of the log-rank test is the hazard ratio of the Cox model [@rufibach2019].
Thus, while the log-rank test may still be applied, the interpretation of the associated effect estimate becomes ambiguous.


## Restricted Mean Survival Time {#sec-rmst}

We now address the restricted mean survival time (RMST) and its contrasts as alternative effect measures for the hazard ratio as it is defined in (@eq-phr).
Mathematically, the RMST is the expectation of the transformation $f(T \,|\, t^*) = \min(T,\, t^*)$ of the random variable $T$ where $t^*$ is the restriction time that needs to be specified by the researcher.
The RMST can be interpreted as the expected survival time from the time origin $0$ up to the restriction time $t^*$ [@royston2011].
Using exemplary numbers, @royston2011 provide a clinical interpretation of the RMST:
"[Y]our life expectancy with X treatment and Z disease over the next 18 months is 9 months".
Moreover, considering a two-sample comparison based on the RMST difference, they further extend this interpretation [@royston2011]:
"[T]reatment A increases your life expectancy during the next 18 months by 2 months, compared with treatment B."
The RMST can be calculated by integrating the survival function from time $0$ to $t^*$ [@royston2011], i.e.
$$
\mu(t^*) = \expect[\min(T,\, t^*)] = \int_0^{t^*} S(u) \,du
\, .
$$ {#eq-rmst}
The reason for considering a restricted version of the mean is right-censoring of the survival data.
For the nonparametric Kaplan-Meier estimator of the survival function to reach $0$ and therefore be able to estimate an unrestricted mean, the largest event time needs to be uncensored, which is rarely the case.
On the other hand, employing parametric models in survival analysis is often a difficult task.
Even if we had a model with a decent in-sample fit, we cannot be sure whether the extrapolation of that model to the tail of the survival distribution is adequate [@royston2011].

Using the definition (@eq-rmst) of the RMST, actual effect measures can be obtained by considering ratios $\mu_1(t^*) / \mu_0(t^*)$ or differences $\mu_1(t^*) - \mu_0(t^*)$ of the RMSTs, e.g. between two treatment groups [@uno2014].
The main advantage of using the RMST and group contrasts thereof in comparison to the prevalent hazard ratio is that it is a model-free effect measure and has a clear clinical interpretation, though this might be subject to discussion [@freidlin2019].
To further enhance the understanding of the RMST, @fig-rmst provides a visual demonstration of it based on survival functions of the exponential distribution.
The left panel depicts the situation for a single sample while the right panel illustrates the two-sample RMST difference as an effect measure.

```{r}
#| label: fig-rmst
#| fig-cap: "Illustration of the RMST: The colored area under the survival curve (left panel) depicts the one-sample RMST. The grayed area between the two survival curves (right panel) illustrates the RMST difference between two populations"
#| fig-scap: "Illustration of the RMST: one-sample RMST (left) and two-sample RMST difference (right)"
#| fig-width: 10
#| fig-height: 5

# One sample plot ----

lambda0 = 0.2

dt = data.table(
  time = seq(0, 10.5, length.out = 250),
  surv = exp(- (lambda0 * seq(0, 10.5, length.out = 250)))
)

p1 = ggplot(dt, aes(time, surv)) +
  geom_line(color = "#E69F00", linewidth = 1.1) +
  geom_area(color = "#E69F00", fill = "#E69F00", alpha = 0.4, data = dt[time <= 10]) +
  # Indicator line for RMST cutoff
  geom_vline(
    xintercept = 10, linewidth = 0.9,
    linetype = "longdash", color = "#222222"
  ) +
  # Fine-tuning of axes
  scale_x_continuous(
    breaks = seq(0, 10, by = 2.5),
    limits = c(0, 10.5),
    expand = expansion(mult = c(0, 0), add = c(0.5, 0))
  ) +
  scale_y_continuous(limits = 0:1) +
  # Axes labels
  labs(x = "\nTime", y = "Survival probability\n")


# Two-sample plot ----

lambda0 = 0.2
lambda1 = 0.1

dt = data.table(time = seq(0, 10.5, length.out = 250))
dt[, `:=`(surv0 = exp(- (lambda0 * time)), surv1 = exp(- (lambda1 * time)))]

p2 = ggplot(dt) +
  geom_ribbon(
    aes(x = time, ymin = surv0, ymax = surv1), data = dt[time <= 10],
    color = "#999999", fill = "#999999", alpha = 0.5
  ) +
  geom_line(aes(time, surv0, color = "T0"), linewidth = 1.1) +
  geom_line(aes(time, surv1, color = "T1"), linewidth = 1.1) +
  scale_color_manual(
    name = NULL,
    values = c("T0" = "#E69F00", "T1" = "#56B4E9"),
    labels = expression(T[0] ~ tilde("") ~ Exp(0.2), T[1] ~ tilde("") ~ Exp(0.1))
  ) +
  # Indicator line for RMST cutoff
  geom_vline(
    xintercept = 10, linewidth = 0.9,
    linetype = "longdash", color = "#222222"
  ) +
  # Fine-tuning of axes
  scale_x_continuous(
    breaks = seq(0, 10, by = 2.5),
    limits = c(0, 10.5),
    expand = expansion(mult = c(0, 0), add = c(0.5, 0))
  ) +
  scale_y_continuous(limits = 0:1) +
  # Axes labels
  labs(x = "\nTime", y = "Survival probability\n")


# Combine plots ----

p2 = p2 +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

wrap_plots(p1, p2, ncol = 2) +
  plot_layout(axis_titles = "collect", guides = "collect") &
  theme(legend.position = "top")
```

Now, the question remains how to estimate $\mu(t^*)$ for an observed data set.
Broadly, a point estimator for $\mu(t^*)$ can be obtained by integrating an estimate of the survival function:
$$
\muhat(t^*) = \int_0^{t^*} \hat{S}(u) \, du
$$
In principle, any estimator $\hat{S}$ can be applied but most commonly the non-parametric Kaplan-Meier estimator [@kaplan1958] is used:
$$
\hat{S}(t) = 
\begin{cases}
  1 & \text{for } t < t_1 \\
  \prod_{t_j \leq t} \left(1 - \frac{d_j}{Y_j}\right) & \text{for } t \geq t_1
\end{cases}
$$
Here, $t_j$ ($j = 1, 2, \ldots, m$) denotes the ordered and distinct event times observed in the survival data.
Moreover, $Y_j$ denotes the number of individuals at risk just prior to $t_j$ and $d_j$ the number of observed events at $t_j$. 
The reasons for the usage of the Kaplan-Meier estimator for estimating the RMST are twofold.
On the one hand, using a non-parametric estimator avoids making any possibly false assumptions about the shape of the survival curve.
On the other hand, using this estimator, closed-form solutions for both, the point and the variance estimator, are available and there is no need to rely on computational methods like numerical integration or resampling.
Specifically, the point estimator utilizing the Kaplan-Meier estimator of the survival function can be written as [@hasegawa2020]
$$
\muhat(t^*) = \sum_{j=0}^D (t_{j+1} - t_j) \hat{S}(t_j) \, ,
$$ {#eq-pointest}
where, like before, $t_1 < t_2 < \ldots < t_D$ denote the ordered and distinct event times observed in the survival data and $t_{D+1} = t^*$.
An estimator for the variance of the point estimator (@eq-pointest) based on Greenwood's formula is given by [@hasegawa2020]
$$
\Varhat[\muhat(t^*)] = \sum_{j=1}^D 
\left[ \sum_{i=j}^D (t_{i+1} - t_i) \hat{S}(t_i) \right]^2
\frac{d_j}{Y_j (Y_j - d_j)}
\, .
$$ {#eq-varest1}
Alternatively, the variance can be estimated by
$$
\Varhat[\muhat(t^*)] = \sum_{j=1}^D 
\left[ \sum_{i=j}^D (t_{i+1} - t_i) \hat{S}(t_i) \right]^2
\frac{d_j}{Y_j^2}
\, ,
$${#eq-varest2}
which is derived by plugging in the Nelson-Aalen estimator of the cumulative hazard rate into the theoretical variance formula [@ditzhaus2023].
Both variance estimators are valid but since most authors employ the estimator (@eq-varest1) we use it here per default as well.

[^1]: The length (number of columns) of the vector (design matrix) may be increased by one in the context of regression modelling for the inclusion of an intercept term.
